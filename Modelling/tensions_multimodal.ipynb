{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6510bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator, StrMethodFormatter\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "\n",
    "from scipy.stats import gaussian_kde, chi2, norm\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff6d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_param(mean, err_l, err_u, n=50000, allow_negative=False, rng=None):\n",
    "    rng = np.random.default_rng(rng)\n",
    "    samples = np.where(\n",
    "        rng.random(n) < 0.5,\n",
    "        rng.normal(mean, err_l, size=n),\n",
    "        rng.normal(mean, err_u, size=n)\n",
    "    )\n",
    "    if not allow_negative:\n",
    "        samples = np.clip(samples, 0, None)\n",
    "    return samples\n",
    "\n",
    "def build_samples(df, param_names, n=50000, rng=None):\n",
    "    samples = {}\n",
    "    for p in param_names:\n",
    "        allow_negative = (p == 'texp')  # only texp may go negative\n",
    "        samples[p] = sample_param(df[p].values[0], \n",
    "                                  df[p + '_l'].values[0],\n",
    "                                  df[p + '_u'].values[0],\n",
    "                                  n=n, allow_negative=allow_negative, rng=rng)\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef31473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tension_from_two_posteriors(\n",
    "    samples1, samples2, weights1=None, weights2=None,\n",
    "    n_pairs=50000, bandwidth='scott', rng=None):\n",
    "    \"\"\"\n",
    "    Compute tension between two 2-D posteriors using HPD mass of delta=0.\n",
    "\n",
    "    samples1, samples2 : arrays (N,2) and (M,2) of (H,m) samples\n",
    "    weights1, weights2 : optional 1-D weights (nonnegative), length N and M\n",
    "    n_pairs            : number of independent (i,j) pairs to draw for deltas\n",
    "    bandwidth         : KDE bw for gaussian_kde ('scott', 'silverman', or float)\n",
    "    rng               : np.random.Generator for reproducibility\n",
    "\n",
    "    Returns dict with:\n",
    "      alpha, n_sigma_2d, n_sigma_1d,\n",
    "      density_at_zero, map_delta, density_map_delta\n",
    "      alpha_gauss, n_sigma_2d_gauss, n_sigma_1d_gauss (Gaussian quick check)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    s1 = np.asarray(samples1); s2 = np.asarray(samples2)\n",
    "    assert s1.shape[1]==2 and s2.shape[1]==2, \"Use 2-D samples.\"\n",
    "\n",
    "    N, M = len(s1), len(s2)\n",
    "\n",
    "    # Normalize weights if given\n",
    "    if weights1 is not None:\n",
    "        w1 = np.asarray(weights1, float); w1 = np.clip(w1, 0, np.inf)\n",
    "        w1 /= w1.sum()\n",
    "    else:\n",
    "        w1 = None\n",
    "    if weights2 is not None:\n",
    "        w2 = np.asarray(weights2, float); w2 = np.clip(w2, 0, np.inf)\n",
    "        w2 /= w2.sum()\n",
    "    else:\n",
    "        w2 = None\n",
    "\n",
    "    # Draw independent indices for the convolution via random pairing\n",
    "    i = rng.integers(0, N, size=n_pairs)\n",
    "    j = rng.integers(0, M, size=n_pairs)\n",
    "\n",
    "    deltas = s1[i] - s2[j]                       # shape (n_pairs, 2)\n",
    "    deltas_T = deltas.T                          # (2, n_pairs)\n",
    "\n",
    "    # Pair weights = product of marginals for independent draws\n",
    "    if (w1 is None) and (w2 is None):\n",
    "        w = None\n",
    "    else:\n",
    "        wi = (w1[i] if w1 is not None else np.full(n_pairs, 1.0/N))\n",
    "        wj = (w2[j] if w2 is not None else np.full(n_pairs, 1.0/M))\n",
    "        w  = wi * wj\n",
    "        w /= w.sum()\n",
    "\n",
    "    # KDE on deltas\n",
    "    kde = gaussian_kde(deltas_T, weights=w, bw_method=bandwidth)\n",
    "    dens_deltas = kde.evaluate(deltas_T)         # (n_pairs,)\n",
    "    dens_zero   = float(kde.evaluate(np.zeros((2,1)))[0])  # at delta=(0,0)\n",
    "\n",
    "    # MAP delta (mode among the sampled deltas)\n",
    "    imap = np.argmax(dens_deltas)\n",
    "    map_delta = deltas[imap]\n",
    "    dens_map  = float(dens_deltas[imap])\n",
    "\n",
    "    # HPD mass through zero: α = P(f >= f(0))\n",
    "    if w is None:\n",
    "        alpha = np.mean(dens_deltas >= dens_zero)\n",
    "    else:\n",
    "        alpha = float(w[dens_deltas >= dens_zero].sum())\n",
    "\n",
    "    # Convert to sigma\n",
    "    n_sigma_2d = np.sqrt(chi2.ppf(alpha, df=2))\n",
    "    n_sigma_1d = norm.ppf((1 + alpha) / 2.0)\n",
    "\n",
    "    # -------- Gaussian quick-check (for reference) --------\n",
    "    mu1 = (s1 if w1 is None else (s1 * w1[:,None]).sum(axis=0)) if w1 is not None else s1.mean(axis=0)\n",
    "    mu2 = (s2 if w2 is None else (s2 * w2[:,None]).sum(axis=0)) if w2 is not None else s2.mean(axis=0)\n",
    "    C1  = np.cov(s1.T, aweights=(w1 if w1 is not None else None), bias=False)\n",
    "    C2  = np.cov(s2.T, aweights=(w2 if w2 is not None else None), bias=False)\n",
    "    dmu = mu1 - mu2\n",
    "    Csum = C1 + C2\n",
    "    # Regularize in case of near-singularity\n",
    "    eps = 1e-12 * np.trace(Csum)\n",
    "    Csum_reg = Csum + eps * np.eye(2)\n",
    "    T2 = float(dmu @ np.linalg.solve(Csum_reg, dmu))  # Δχ² under Gaussian approx\n",
    "    alpha_g = float(chi2.cdf(T2, df=2))\n",
    "    n_sigma_2d_g = np.sqrt(T2)\n",
    "    n_sigma_1d_g = norm.ppf((1 + alpha_g) / 2.0)\n",
    "\n",
    "    return dict(\n",
    "        alpha=alpha, n_sigma_2d=n_sigma_2d, n_sigma_1d=n_sigma_1d,\n",
    "        density_at_zero=dens_zero, map_delta=map_delta, density_map_delta=dens_map,\n",
    "        alpha_gauss=alpha_g, n_sigma_2d_gauss=n_sigma_2d_g, n_sigma_1d_gauss=n_sigma_1d_g\n",
    "    )\n",
    "    \n",
    "def compute_tension_for_param(samples1, samples2, mode='1d'):\n",
    "    if mode == '1d':\n",
    "        # Simple Gaussian sigma comparison\n",
    "        mean1, mean2 = np.mean(samples1), np.mean(samples2)\n",
    "        std1, std2 = np.std(samples1), np.std(samples2)\n",
    "        delta = abs(mean1 - mean2)\n",
    "        sigma = np.sqrt(std1**2 + std2**2)\n",
    "        return delta / sigma  # n_sigma_1d\n",
    "    else:\n",
    "        # Convert to 2D and use full KDE method\n",
    "        S1 = np.column_stack([samples1[:,0], samples1[:,1]])\n",
    "        S2 = np.column_stack([samples2[:,0], samples2[:,1]])\n",
    "        return tension_from_two_posteriors(S1, S2)['n_sigma_2d']\n",
    "    \n",
    "# Example values with asymmetric uncertainties:\n",
    "\n",
    "def compute_asymmetric_tension(a, a_err_plus, a_err_minus,\n",
    "                                b, b_err_plus, b_err_minus):\n",
    "\n",
    "    if a > b:\n",
    "        sigma_eff = np.sqrt(a_err_minus**2 + b_err_plus**2)\n",
    "    else:\n",
    "        sigma_eff = np.sqrt(a_err_plus**2 + b_err_minus**2)\n",
    "\n",
    "    # Sigma tension\n",
    "    delta = abs(a - b)\n",
    "    tension_sigma = delta / sigma_eff\n",
    "    return tension_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf76e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Mej', 'Mej_u', 'Mej_l', \n",
    "           'vej', 'vej_u', 'vej_l', \n",
    "           'Tmin', 'Tmin_u', 'Tmin_l',\n",
    "           'texp', 'texp_u', 'texp_l',\n",
    "           'Mscm', 'Mscm_u', 'Mscm_l',\n",
    "           's', 's_u', 's_l',\n",
    "           'rho0', 'rho0_u', 'rho0_l',\n",
    "           'R0', 'R0_u', 'R0_l',\n",
    "           'n', 'n_u', 'n_l',\n",
    "           'N_H', 'N_H_u', 'N_H_l',\n",
    "           'sigma', 'sigma_u', 'sigma_l']\n",
    "\n",
    "\n",
    "vxm_list = [38.81, 6.55, 6.02, 6918, 161, 157, 6310, 147, 144,\n",
    "            -0.86, 0.08, 0.09, 1.48, 0.14, 0.13, 1.40, 0.08, 0.08,\n",
    "            3.02, 6.53, 1.92, 12.3, 14, 6.9, 7.46, 0.47, 0.29, \n",
    "            5.57, 0.70, 0.63, 0.126, 0.006, 0.008]\n",
    "\n",
    "rv_list = [20.1, 19, 14.9, 4721, 3750, 2022, 2587, 4960, 2570, \n",
    "           -10.4, 5.7, 7.7, 1.26, 6.68, 0.92, 1.37, 0.67, 0.93,\n",
    "           6.31, 0.44, 5.81, 13.1, 35.2, 9.7, 9.44, 1.79, 1.80,\n",
    "           0.08, 6.23, 0.08, 0.100, 0.151, 0.005]\n",
    "\n",
    "vxm_params_df = pd.DataFrame([vxm_list], columns = columns)\n",
    "rv_params_df = pd.DataFrame([rv_list], columns = columns)\n",
    "\n",
    "param_names = ['Mej','vej','Tmin','texp','Mscm','s','rho0','R0','n','N_H','sigma']\n",
    "\n",
    "samples_vxm = build_samples(vxm_params_df, param_names)\n",
    "samples_rv  = build_samples(rv_params_df, param_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0efc5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tension_results = {}\n",
    "\n",
    "for p in param_names:\n",
    "    a = vxm_params_df[p].values[0]\n",
    "    a_err_plus = vxm_params_df[p + '_u'].values[0]\n",
    "    a_err_minus = vxm_params_df[p + '_l'].values[0]\n",
    "    b = rv_params_df[p].values[0]\n",
    "    b_err_plus = rv_params_df[p + '_u'].values[0]\n",
    "    b_err_minus = rv_params_df[p + '_l'].values[0]\n",
    "    \n",
    "    tension_results[p] = compute_asymmetric_tension(a, a_err_plus, a_err_minus, b, b_err_plus, b_err_minus)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98b1a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mej: 0.94 sigma\n",
      "vej: 0.59 sigma\n",
      "Tmin: 0.75 sigma\n",
      "texp: 1.67 sigma\n",
      "Mscm: 0.03 sigma\n",
      "s: 0.04 sigma\n",
      "rho0: 0.38 sigma\n",
      "R0: 0.05 sigma\n",
      "n: 1.06 sigma\n",
      "N_H: 0.88 sigma\n",
      "sigma: 0.17 sigma\n"
     ]
    }
   ],
   "source": [
    "for t in tension_results:\n",
    "    print(f\"{t}: {tension_results[t]:.2f} sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mej: 0.35 sigma\n",
    "# vej: 0.23 sigma\n",
    "# Tmin: 0.38 sigma\n",
    "# texp: 0.68 sigma\n",
    "# Mscm: 0.16 sigma\n",
    "# s: 0.01 sigma\n",
    "# rho0: 0.27 sigma\n",
    "# R0: 0.12 sigma\n",
    "# n: 0.16 sigma\n",
    "# N_H: 0.60 sigma\n",
    "# sigma: 0.07 sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ea697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2           = 8.39303\n",
      "sqrt(T2)     = 2.89707    (geometric norm; not a p-value unless k=1)\n",
      "df (k)       = 11\n",
      "p-value      = 0.677724\n",
      "equiv sigma (2-sided) = 0.4156\n",
      "equiv sigma (1-sided) = -0.4613\n"
     ]
    }
   ],
   "source": [
    "X1 = np.column_stack([samples_vxm[p] for p in param_names])  # shape (N, k)\n",
    "X2 = np.column_stack([samples_rv[p] for p in param_names])   # shape (N, k)\n",
    "\n",
    "# Means and covariances\n",
    "mu1 = X1.mean(axis=0)\n",
    "mu2 = X2.mean(axis=0)\n",
    "dmu = mu1 - mu2\n",
    "\n",
    "# Use rowvar=False for cov with shape (k,k)\n",
    "C1 = np.cov(X1, rowvar=False, bias=False)\n",
    "C2 = np.cov(X2, rowvar=False, bias=False)\n",
    "Csum = C1 + C2\n",
    "\n",
    "# Regularize if near-singular (tiny ridge)\n",
    "k = Csum.shape[0]\n",
    "eps = 1e-12 * np.trace(Csum)   # scale of regularization; adjust if you need\n",
    "Csum_reg = Csum + eps * np.eye(k)\n",
    "\n",
    "# Compute T^2 (Mahalanobis / chi-square)\n",
    "T2 = float(dmu @ np.linalg.solve(Csum_reg, dmu))\n",
    "\n",
    "# p-value for chi-square with k degrees of freedom (upper-tail)\n",
    "p_value = 1.0 - chi2.cdf(T2, df=k)\n",
    "\n",
    "# Convert p-value to equivalent Gaussian sigma:\n",
    "# - two-sided equivalent sigma (common to report): use isf(p/2)\n",
    "# - one-sided equivalent sigma: use isf(p)\n",
    "sigma_equiv_two_sided = norm.isf(p_value / 2.0)\n",
    "sigma_equiv_one_sided = norm.isf(p_value)\n",
    "\n",
    "# For quick numeric context, also show sqrt(T2) (geometric norm)\n",
    "sqrt_T2 = np.sqrt(T2)\n",
    "\n",
    "print(f\"T2           = {T2:.6g}\")\n",
    "print(f\"sqrt(T2)     = {sqrt_T2:.6g}    (geometric norm; not a p-value unless k=1)\")\n",
    "print(f\"df (k)       = {k}\")\n",
    "print(f\"p-value      = {p_value:.6g}\")\n",
    "print(f\"equiv sigma (2-sided) = {sigma_equiv_two_sided:.4g}\")\n",
    "print(f\"equiv sigma (1-sided) = {sigma_equiv_one_sided:.4g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d21e7005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8970845181652622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sigma_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42147e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max marginal z: 1.443367911766139\n",
      "all marginal z: [1.06807594 0.74962898 1.02414233 1.4156085  0.25551459 0.02083806\n",
      " 0.53739927 0.20533953 1.07485029 1.44336791 0.16144196]\n",
      "T2_indep = 8.41690655081964  -> n_multi_indep = 2.9011905402471654\n",
      "T2 full = 8.3930332714797  -> n_multi = 2.8970732250807365\n",
      "p-value (chi2, df=k) = 0.6777236564445563\n",
      "Equivalent 1D two-sided sigma = 0.4155714025031945\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2, norm\n",
    "\n",
    "# samples_vxm, samples_rv are dicts of shape (n_samples,) per parameter\n",
    "\n",
    "# 1) compute marginal means, stds, and marginal z-scores\n",
    "means1 = np.array([samples_vxm[p].mean() for p in param_names])\n",
    "means2 = np.array([samples_rv[p].mean() for p in param_names])\n",
    "std1   = np.array([samples_vxm[p].std(ddof=1) for p in param_names])\n",
    "std2   = np.array([samples_rv[p].std(ddof=1) for p in param_names])\n",
    "\n",
    "dmu = means1 - means2\n",
    "marginal_z = np.abs(dmu) / np.sqrt(std1**2 + std2**2)  # vector of n_i\n",
    "\n",
    "print(\"max marginal z:\", marginal_z.max())\n",
    "print(\"all marginal z:\", marginal_z)\n",
    "\n",
    "# 2) independent-sum bound\n",
    "T2_indep = np.sum(marginal_z**2)\n",
    "print(\"T2_indep =\", T2_indep, \" -> n_multi_indep =\", np.sqrt(T2_indep))\n",
    "\n",
    "# 3) full multivariate Mahalanobis\n",
    "X1 = np.column_stack([samples_vxm[p] for p in param_names])  # shape (N, k)\n",
    "X2 = np.column_stack([samples_rv[p] for p in param_names])\n",
    "\n",
    "mu1 = X1.mean(axis=0)\n",
    "mu2 = X2.mean(axis=0)\n",
    "C1 = np.cov(X1, rowvar=False, bias=False)\n",
    "C2 = np.cov(X2, rowvar=False, bias=False)\n",
    "Csum = C1 + C2\n",
    "# regularize slightly if needed\n",
    "eps = 1e-12 * np.trace(Csum)\n",
    "Csum_reg = Csum + eps * np.eye(Csum.shape[0])\n",
    "\n",
    "T2 = float(dmu @ np.linalg.solve(Csum_reg, dmu))\n",
    "n_multi = np.sqrt(T2)\n",
    "\n",
    "pval = 1.0 - chi2.cdf(T2, df=len(param_names))\n",
    "# convert to equivalent two-sided Gaussian sigma\n",
    "n_equiv_1d = norm.isf(pval/2.0)\n",
    "\n",
    "print(\"T2 full =\", T2, \" -> n_multi =\", n_multi)\n",
    "print(\"p-value (chi2, df=k) =\", pval)\n",
    "print(\"Equivalent 1D two-sided sigma =\", n_equiv_1d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6448d686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8970732250807365"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "504d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tension_values = []\n",
    "\n",
    "for p in param_names:\n",
    "    tension_values.append(tension_results[p])\n",
    "    \n",
    "tension_values = np.array(tension_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb2a15aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 = 6.665304022450252  df = 11\n",
      "global p = 0.8255042249785753\n",
      "equivalent sigma = 0.22047116745532652\n"
     ]
    }
   ],
   "source": [
    "k = len(tension_values)\n",
    "\n",
    "chi2_obs = np.nansum(tension_values**2)\n",
    "p_chi2 = 1 - chi2.cdf(chi2_obs, df=k)      # tail prob\n",
    "sigma_eq = norm.isf(p_chi2/2)              # two-sided -> equivalent sigma\n",
    "\n",
    "print(\"chi2 =\", chi2_obs, \" df =\", k)\n",
    "print(\"global p =\", p_chi2)\n",
    "print(\"equivalent sigma =\", sigma_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3f72ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7784193788143119"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(chi2_obs/11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0049f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "au_to_cm = 1.495978707e13  # cm in one AU\n",
    "solar_mass_to_grams = 1.98847e33  # grams in one solar mass\n",
    "\n",
    "mcsm_samples = sample_param(1.48, 0.13, 0.14, n=50000, allow_negative=False, rng=None)\n",
    "rho0_samples = sample_param(3.02e-12, 1.92e-12, 6.53e-12, n=50000, allow_negative=False, rng=None)\n",
    "r0_samples = sample_param(12.3, 6.9, 14, n=50000, allow_negative=False, rng=None)\n",
    "s_samples = sample_param(1.40, 0.08, 0.08, n=50000, allow_negative=False, rng=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac22464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/pg_c9mqn3gn45gn_zmvy9w9cvfsx9j/T/ipykernel_11100/3524349800.py:4: RuntimeWarning: divide by zero encountered in divide\n",
      "  rcsm = ((3*mcsm_samples*solar_mass_to_grams)/+ r0_samples**3)**(1/3)\n"
     ]
    }
   ],
   "source": [
    "denom = (4 * np.pi * rho0_samples * (r0_samples * au_to_cm)**(s_samples)) \n",
    "denom[denom == 0] = 1e9  # avoid division by zero\n",
    "\n",
    "rcsm = ((3*mcsm_samples*solar_mass_to_grams)/+ r0_samples**3)**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c30ad54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+09, 1.00000000e+09, 6.39615690e+08, ...,\n",
       "       1.79675309e+09, 1.89057208e+11, 6.16915090e+10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "928d86d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0011210642992160456, 0.0004977869896140504, 0.004237792638545911)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(rcsm, 50)/au_to_cm, (np.nanpercentile(rcsm, 50) - np.nanpercentile(rcsm, 16))/au_to_cm, (np.nanpercentile(rcsm, 84) - np.nanpercentile(rcsm, 50))/au_to_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8ad9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_mass_to_grams = 1.98847e33  # grams in one solar mass\n",
    "\n",
    "epsilon = 0.5\n",
    "\n",
    "Eej = epsilon**(-2/(n_samples - 3)) * (solar_mass_to_grams * mej_samples)**((n_samples-5)/(n_samples-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "334b51c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.320023445431379e+19, 2.2268655759949582e+19, 3.3320022095361534e+20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(Eej, 50), np.nanpercentile(Eej, 50) - np.nanpercentile(Eej, 16), np.nanpercentile(Eej, 84) - np.nanpercentile(Eej, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a8ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
